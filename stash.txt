python xtts_clone.py --ref samples/output.wav --text "Hello world" --out out.wav --lang en

‚Ä¢	--ref ‚Üí path to your voice reference audio (your 49-min recording).

set -a; source .env; set +a // load .env vars into 


	‚Ä¢	For maximum consistency: temperature=0.0, top_p=0.0 (greedy).
	‚Ä¢	For slight expressiveness but stable: temperature=0.1‚Äì0.2, top_p=0.7‚Äì0.9.
	‚Ä¢	Keep using your cached conditioning (gpt_cond_latent + speaker_embedding) so the voice stays the same; only the delivery changes.



----------------------------------------------------
1. The Core Players
	‚Ä¢	Coqui TTS Synthesizer
This is the object that takes your text + voice embedding and actually generates audio. Think of it like the ‚Äúbrain‚Äù of TTS.
	‚Ä¢	Speaker Embedding (conditioning.pt)
This is a vector representation of your 49-minute voice sample. It‚Äôs like a ‚Äúvoice DNA‚Äù file ‚Äî a fingerprint that tells the model how to sound.
Once computed, it can be reused forever, which is why caching it is so powerful.
	‚Ä¢	speak.py
This script loads both the model and the cached embedding, then feeds them text ‚Üí audio.




-------------------------------------------------------


Perfect question üëç this is exactly the repeatability we want.

Right now your flow is basically two scripts:
	1.	Prep a reference voice (once per speaker)
	‚Ä¢	Run prep_ref.py (the script we wrote earlier).
	‚Ä¢	Example:


python prep_ref.py --ref /absolute/path/to/voice2.wav --out conditioning/voice2.pt



	‚Ä¢	That gives you a cached file with both gpt_cond_latent and speaker_embedding for that speaker.

	2.	Synthesize speech with that cached voice
	‚Ä¢	Run speak.py and pass in the .pt you just created:



python speak.py --text "This is the second voice speaking." \
                --speaker conditioning/voice2.pt \
                --out out/voice2_test.wav



----------------------------------------------------------------------------

docker build --no-cache -t tts-service .

docker build --no-cache --progress=plain -t tts-service . | tee build.log


docker run --rm -it -p 8000:8000 tts-service

1. Run an interactive shell inside the container
docker run -it --rm tts-service bash

2. Explore with VSCode‚Äôs Docker extension
	‚Ä¢	Install the Docker extension in VSCode (by Microsoft).
	‚Ä¢	It gives you a Docker tab where you can expand: Images ‚Üí Containers ‚Üí Filesystem.
	‚Ä¢	You can directly open files inside containers and even attach a terminal.


3. Use docker exec on a running container

If your container is already running:
docker exec -it <container_id_or_name> bash

Find the container ID with:
docker ps

4. Export image to inspect like a project
If you want the entire image as a folder tree on disk:
docker create --name temp tts-service
docker export temp | tar -xvf - -C ./docker-rootfs
docker rm temp



------------------------------------------------------------

curl -X POST "http://localhost:8000/speak" \
  -F voice=@conditioning/conditioning.pt \
  -F text="Hello from the Dockerized XTTS API." \
  -F lang=en -F temp=0.1 -F top_p=0.0 \
  --output out/hello.wav